import requests
from bs4 import BeautifulSoup
from langchain.schema import Document

# Confluence REST API setup
CONFLUENCE_BASE_URL = "https://your-confluence-domain.atlassian.net/wiki/rest/api/content/"
API_USERNAME = "your-email"
API_TOKEN = "your-api-token"

# Function to fetch Confluence page content
def fetch_confluence_page(page_id):
    url = f"{CONFLUENCE_BASE_URL}{page_id}?expand=body.view"
    response = requests.get(url, auth=(API_USERNAME, API_TOKEN))
    if response.status_code == 200:
        data = response.json()
        return data['body']['view']['value']
    else:
        print(f"Error fetching page {page_id}: {response.status_code}")
        return None

# Function to extract paragraphs as documents from the Confluence page
def extract_documents_from_html(html_content, page_id):
    soup = BeautifulSoup(html_content, "lxml")  # Parse the HTML using BeautifulSoup
    paragraphs = soup.find_all("p")  # Find all <p> tags (paragraphs)

    documents = []
    
    # Iterate through paragraphs and create a LangChain Document for each
    for paragraph in paragraphs:
        text = paragraph.get_text(strip=True)
        if text:
            # Metadata can include additional information such as the page ID or section info
            metadata = {"page_id": page_id}
            document = Document(page_content=text, metadata=metadata)
            documents.append(document)
    
    return documents

# Function to fetch and process a Confluence page as LangChain Documents
def scrape_confluence_page_to_documents(page_id):
    page_content = fetch_confluence_page(page_id)
    if page_content:
        documents = extract_documents_from_html(page_content, page_id)
        return documents
    return []

# Example usage
page_id = "123456"  # Replace with your actual Confluence page ID
documents = scrape_confluence_page_to_documents(page_id)

# Output the list of documents
print("Extracted LangChain Documents:")
for i, doc in enumerate(documents, 1):
    print(f"Document {i}:")
    print(f"Content: {doc.page_content}")
    print(f"Metadata: {doc.metadata}")
    print("-" * 40)
